\chapter{Conclusion}
\label{chp:conclusion} 

\section{Problem Description Fulfillment}

\subsubsection{Point 1 - Theory and state-of-the-art Solutions}

Chapter \ref{chp:maintenance} presented some recent projects on robotic maintenance and inspection. Both \ac{MIMROex} and Sensabot resembles the prototype used in this project. Of these two, \ac{MIMROex} might be the best source of inspiration when considering new designs and implementations. Industrial maintenance robots are currently capable of teleoperated inspection, and autonomous manipulation of the processes are heavily researched. 

\subsubsection{Point 2 - Selection of Development Tools}

The chosen tools and frameworks are \ac{ROS} for the robot software and Qt for the \ac{OCS}. \ac{ROS} is introduced in chapter \ref{sec:ros}. These tools proved to be suitable for the task at hand. An Android device was used as a supporting tool during testing.

\subsubsection{Point 3 - Test Platform}

The mobile robot platform used in \cite{aspunvik}, \cite{berg} and \cite{lindrup} was used in this project as well. A Kinect sensor and an additional on-board computer was added to the robot. A new shelf structure was placed on the robot in order to accommodate the new equipment. 

\subsubsection{Point 4 - Solutions and Implementations}

Autonomous navigation, localization and mapping is among the fundamental tasks an autonomous robot will face. Visual \ac{SLAM} capabilities were implemented by using \ac{RTAB-Map}, which is presented in section \ref{sec:RTAB-Map}. For navigation, the robot uses the \ac{ROS} navigation stack, which is introduced in section \ref{sec:navigation_theory}. The navigation system receives obstacle information a depth camera and a \ac{LIDAR}. 

\subsubsection{Point 5 - Assessment}

An assessment of the project results is provided in chapter \ref{chp:discussion}. The tests leading up to the assessment, could have been more thorough.

\section{Final Conclusion}



The main goal of this project was to implement a vision based solution to a problem faced by a mobile, autonomous maintenance robot. \ac{SLAM} was chosen as the problem to be solved, as it is one of the fundamental problems a mobile robot must handle.  To meet the goal, the robot was configured to use \ac{ROS} together with \ac{RTAB-Map}, a system for large scale appearance based \ac{SLAM}, developed by IntRoLab. An additional major implementation goal was to achieve autonomous navigation. A third objective was to implement an operator control station (\ac{OCS}) where an operator can monitor and control the robot via a wireless connection. 

\ac{RTAB-Map} is configured to use a Kinect for Xbox 360 in combination with a \ac{LIDAR} to generate 2D occupancy grid maps and 3D point cloud maps of the environments. The current implementation is capable of building maps over multiple sessions. Scan matching from Hector SLAM provides odometry to \ac{RTAB-Map}. Using laser scans as a source of odometry was susceptible to errors in featureless areas, when the robot rounded corners and when people walked by or towards the robot. 

Testing sessions, performed in both a simulator and with a live mobile robot prototype, demonstrated \ac{RTAB-Map}'s ability to build maps and localize the robot within these maps.  Loop closure detection would work when a sufficient amount of visual features were available, but this was often not the case.

Navigation tests on the live robot showed that the robot can navigate successfully in known and structured environments with some room maneuvering space. Navigation performance decreased in cluttered environments, e.g. office environments with many tables placed closely together.

The implementations presented in this thesis is the first attempt at integrating the mobile robot prototype with \ac{ROS}. It is concluded that  \ac{ROS} is a good tool for prototyping, and it is recommended to continue using the framework in following projects on robotic maintenance.



The Kinect and the LIDAR is currently placed in the front of the base. As the Kinect is unable to reliably measure depth any closer than $0.8 m$.

The navigation stack in \ac{ROS} has been configured for this mobile base, and enables the robot to autonomously move towards a goal location in a 2D map. 

