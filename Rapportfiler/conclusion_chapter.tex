\chapter{Conclusion}
\label{chp:conclusion} 

\section{Future Work}

\subsection{Autonomous Non-Destructive Testing}

Advancements in \ac{AI}, big data and machine learning opens up exciting possibilities for autonomous \ac{NDT}. Branches of this technology is usually encountered in the context of image recognition, i.e. teaching machines to understand what they see. The same concepts may be applied to forms of \ac{NDT} besides regular visual sensor input, such as ultra sound or eddy currents for corrosion detection.  

\subsection{Large Scale Kinect Fusion - Kintinous}

Kinect Fusion has great potential for augmented reality. Augmented reality is a concept which blends the real and virtual environment. This opens up opportunities to create realistic and immersive training scenarios for the operators. Unfortunately, Kinect Fusion is limited reconstructing a rather small volume depending on the resolution. By varying the resolution, volumes can at the least cover a normal office desk and at the most cover a small room \cite{keylist}.  

Kintinous...

A guide on how to build Kintinous can be found  at \href{Github}{https://github.com/mp3guy/Kintinuous}. The procedure is complicated, as it usually is for experimental builds. It is recommended to attempt the procedure on a fresh install of Ubuntu 14.04 or 15.04 \cite{Kintinous}.

\subsubsection{Improve the Communication Protocols}

Communication between \ac{ROS} and the XMEGA A3BU, the Bluetooth device and the \ac{OCS} use the same pattern: A start byte \texttt{'':''}, the message with the speed setting and a stop byte \texttt{''Esc''}. In later projects, it could be convenient with a more robust and rich communication protocol with more options for remote operation. 

\subsection{Hardware}

Several hardware-related issues became apparent over the course of the project - especially toward the final weeks. These issues are likely the results of many disconnected projects on the same hardware.

\subsubsection{Kinect Sensor Placement}

This is the first semester in which a Kinect has been used on the robot. At the moment, the sensor is placed directly over the \ac{LIDAR}. Because the depth sensor in the Kinect for XBOX 360 has a minimum range of roughly $0.5 m$, it cannot detect objects within reach of the robot arm. It is recommended to find a new location further back on the robot. 

\subsubsection{On-board Computer}

Because this author used his own computer to control the robot, all features related to \ac{ROS} was removed from the robot at the end of the project. A new computer should be equipped with \ac{SSD} storage

\subsubsection{Wheels}

\begin{wrapfigure}{r}{0.5\textwidth}
	\vspace{-20pt}
	\begin{center}
		\includegraphics[width=0.48\textwidth]{worn_wheel2}
	\end{center}
	
	\caption{Worn omniwheel}
	\label{fig:worn_wheel}
	%\vspace{-20pt}
\end{wrapfigure}

There were mainly two issues with the omni-wheels this semester: They are worn out, and one wheel slipped out of the motor drive shaft. The rubber on a few of the perpendicular rollers is either loose or about to fall off the plastic rims. This causes the robot to shake, which could damage spinning hard disk drives or shake the sensors out of their calibrated positions.   





\section{Task Fulfillment}

\section{Task Fulfilment}

\section{Final Conclusion}