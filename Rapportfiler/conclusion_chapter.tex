\chapter{Conclusion}
\label{chp:conclusion} 

\section{Problem Description Fulfillment}

\subsubsection{Point 1 - Theory and state-of-the-art Solutions}

Chapter \ref{chp:maintenance} presented some recent projects on robotic maintenance and inspection. Both \ac{MIMROex} and Sensabot resembles the prototype used in this project. Of these two, \ac{MIMROex} might be the best source of inspiration when considering new designs and implementations. Industrial maintenance robots are currently capable of teleoperated inspection, and autonomous manipulation of the processes are heavily researched. 

\subsubsection{Point 2 - Selection of Development Tools}

The chosen tools and frameworks are \ac{ROS} for the robot software and Qt for the \ac{OCS}. \ac{ROS} is introduced in chapter \ref{sec:ros}. These tools proved to be suitable for the task at hand. An Android device was used as a supporting tool during testing.

\subsubsection{Point 3 - Test Platform}

The mobile robot platform used in \cite{aspunvik}, \cite{berg} and \cite{lindrup} was used in this project as well. A Kinect sensor and an additional on-board computer was added to the robot. A new shelf structure was placed on the robot in order to accommodate the new equipment. 

\subsubsection{Point 4 - Solutions and Implementations}

Autonomous navigation, localization and mapping is among the fundamental tasks an autonomous robot will face. Visual \ac{SLAM} capabilities were implemented by using \ac{RTAB-Map}, which is presented in section \ref{sec:RTAB-Map}. For navigation, the robot uses the \ac{ROS} navigation stack, which is introduced in section \ref{sec:navigation_theory}. The navigation system receives obstacle information a depth camera and a \ac{LIDAR}. 

\subsubsection{Point 5 - Assessment}

An assessment of the project results is provided in chapter \ref{chp:discussion}.

\section{Final Conclusion}

\subsubsection{Project Objective}

The main objective of this project was to implement a vision based solution to a problem faced by a mobile, autonomous maintenance robot. \ac{SLAM} was chosen as the problem to be solved, as it is one of the fundamental requirements for a mobile robot.  To meet the objective, the robot was configured to use \ac{ROS} together with \ac{RTAB-Map}; a system for large scale appearance based \ac{SLAM}, developed by IntRoLab. An additional major implementation goal was to achieve autonomous navigation. A third objective was to implement an operator control station (\ac{OCS}) where an operator can monitor and control the robot via a wireless connection. 

\subsubsection{Implementations}

\ac{RTAB-Map} is configured to use a Kinect for Xbox 360 in combination with a \ac{LIDAR} to generate 2D occupancy grid maps and 3D point cloud maps of the environments. The current implementation is capable of building maps over multiple sessions. Scan matching from Hector SLAM provides odometry to \ac{RTAB-Map}. 

The robot has been configured to use the navigation stack in \ac{ROS}. The navigation stack configuration enables the robot to plan and follow a path to a simple feasible goal. Additional capabilities include dynamic replanning in the case of obstructions, and 3D obstruction detection based on point clouds.

Three sources of control inputs, besides the navigation stack, was implemented: keyboard inputs for simple testing and input mode settings, commands over a TCP socket from the operator control station (\ac{OCS}) and commands received via a Bluetooth connection. The \ac{OCS} is capable of controlling the robot via the TCP socket, and display live video from the Kinect. An Android device is capable of establishing a Bluetooth connection to the robot, and send velocity commands over this connection.

\subsubsection{Performance and Assessment}

Testing sessions, performed in both a simulator and with a live mobile robot prototype, demonstrated \ac{RTAB-Map}'s ability to build maps and localize the robot within these maps.  Loop closure detection would work when a sufficient amount of visual features were available, but this was often not the case. Using laser scans as a source of odometry was susceptible to errors in featureless areas, when the robot rounded corners and when people walked by or towards the robot. 

Navigation tests on the live robot demonstrated that the robot can navigate successfully in known and structured environments with some maneuvering space. Navigation performance decreased in cluttered environments, e.g. office environments with many tables placed closely together.

\subsubsection{Recommendations}

The mobile base requires an overhaul, and a new drive system should be considered. A new drive system should be dimensioned to support the robots weight and be more rugged, so it can handle uneven surfaces. A holonomic drive system could yield a more agile robot. 

The Kinect and the LIDAR is currently placed in the front of the base. As the Kinect is unable to reliably measure depth any closer than $0.8 m$. A new sensor location should be considered to avoid this blind-zone.

As for \ac{RTAB-Map} there are factors that speak against the method as a mapping system of an offshore robot. The shortcomings  are essentially related to robustness to how the visual appearance of the surrounding change over time. It is recommended to continue testing of \ac{RTAB-Map}. The tests should include different sensor configurations and stereo cameras, as well as different lighting conditions.

The implementations presented in this thesis is the first attempt at integrating the mobile robot prototype with \ac{ROS}. It is concluded that \ac{ROS} is a good tool for prototyping, and it is recommended to continue using the framework in subsequent projects on robotic maintenance. The current software is functional, but not much more. Future projects should strive to increase the system's usability and robustness.

